//this file was generated by ../../../../../../scripts/onnx_generator/OperatorTemplate.py
#include "operator__ai_onnx__gemm__11.h"
#include "tracing.h"
#include "utils.h"
#include "index.h"
#include <omp.h>

operator_status
execute_operator__ai_onnx__gemm__11__T_tensor_float(
    node_context *ctx
)
{
    TRACE_ENTRY(1);

    TRACE_NODE(2, true, ctx->onnx_node);

    /* UNCOMMENT AS NEEDED */

    Onnx__TensorProto *i_A = searchInputByName(ctx, 0);
    Onnx__TensorProto *i_B = searchInputByName(ctx, 1);
    Onnx__TensorProto *i_C = searchInputByName(ctx, 2);

    TRACE_TENSOR(2, true, i_A);
    TRACE_TENSOR(2, true, i_B);
    TRACE_TENSOR(2, true, i_C);

    context_operator__ai_onnx__gemm__11 *op_ctx = (context_operator__ai_onnx__gemm__11 *)ctx->executer_context;

    __attribute__((unused))
    int K = op_ctx->K;
    __attribute__((unused))
    int N = op_ctx->N;
    __attribute__((unused))
    float alpha = op_ctx->alpha;
    __attribute__((unused))
    float beta  = op_ctx->beta;
    __attribute__((unused))
    int transA = op_ctx->transA;
    __attribute__((unused))
    int transB = op_ctx->transB;

    Onnx__TensorProto *o_Y = searchOutputByName(ctx, 0);

    TRACE_TENSOR(2, true, o_Y);

    /* DO CALCULATION HERE */

  if(transB){
    #pragma omp parallel for
    for(int j = 0; j < N; j++){
      float temp = 0.0f;
      for(int i = 0; i < K; i++){
        temp += i_A->float_data[i] * i_B->float_data[j*K + i];
      }
      o_Y->float_data[j] = temp + i_C->float_data[j];
    }
  }else{
    #pragma omp parallel for
    for(int j = 0; j < N; j++){
      float temp = 0.0f;
      for(int i = 0; i < K; i++){
        temp += i_A->float_data[i] * i_B->float_data[i*N + j];
      }
      o_Y->float_data[j] = temp + i_C->float_data[j];
    }
  }

    TRACE_EXIT(1);

    /* CHANGE RETURN CODE IF THIS EXECUTER IS VALID */
    // return OP_ENOSYS;
    return OP_OK;
}